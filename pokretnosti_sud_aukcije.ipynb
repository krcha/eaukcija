{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49134f65-c5fd-403a-a3d2-848eaddcf81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CSV file created: aukcije_pokretnosti.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Function to remove Base64 fields from response data\n",
    "def remove_base64_fields(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: remove_base64_fields(value) for key, value in data.items() if key.lower() != 'base64'}\n",
    "    elif isinstance(data, list):\n",
    "        return [remove_base64_fields(item) for item in data]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Function to process a single auction ID to fetch, clean, and extract relevant data\n",
    "def process_auction_id(auction_id, headers):\n",
    "    url = \"https://eaukcija.sud.rs/WebApi.Proxy/api/EAukcija/GetMovablePropertyDetails\"\n",
    "    data_payload = {\"AuctionId\": auction_id, \"Role\": None}\n",
    "    response = requests.post(url, headers=headers, json=data_payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        cleaned_data = remove_base64_fields(response.json())\n",
    "        if 'Data' in cleaned_data:\n",
    "            data_section = cleaned_data['Data']\n",
    "            category_data = data_section.get(\"Category\", {})\n",
    "            place_data = data_section.get(\"Place\", {})\n",
    "            return {\n",
    "                \"ExecutorName\": data_section.get(\"ExecutorName\", \"\"),\n",
    "                \"EstimatedPrice\": data_section.get(\"EstimatedPrice\", \"\"),\n",
    "                \"AuctionNumber\": data_section.get(\"AuctionNumber\", \"\"),\n",
    "                \"Id\": data_section.get(\"Id\", \"\"),\n",
    "                \"Description\": data_section.get(\"Description\", \"\"),\n",
    "                \"NameCategory\": category_data.get(\"Name\", \"\"),\n",
    "                \"Code\": place_data.get(\"Code\", \"\"),\n",
    "                \"Name\": place_data.get(\"Name\", \"\"),\n",
    "                \"ZipCode\": place_data.get(\"ZipCode\", \"\"),\n",
    "                \"Municipality\": place_data.get(\"Municipality\", \"\"),\n",
    "                \"Cadastral\": place_data.get(\"Cadastral\", \"\"),\n",
    "                \"ParcelNumber\": place_data.get(\"ParcelNumber\", \"\")\n",
    "            }\n",
    "    else:\n",
    "        print(f\"Failed to process AuctionId: {auction_id}, Status Code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# Initial setup: URL, headers, and first request to determine TotalCount\n",
    "url = \"https://eaukcija.sud.rs/WebApi.Proxy/api/EAukcija/GetAuctionsByCategoryId\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"accept-language\": \"en,en-US;q=0.9,sr;q=0.8,bs;q=0.7,hr;q=0.6,fi;q=0.5\",\n",
    "    \"content-type\": \"application/json;charset=UTF-8\"\n",
    "    #\"authorization\": \"bearer YOUR_ACCESS_TOKEN\",  # Replace with your actual token\n",
    "}\n",
    "initial_data = {\"CategoryId\": \"2\", \"ItemCount\": 1, \"PageCount\": \"1\"}\n",
    "response = requests.post(url, json=initial_data, headers=headers)\n",
    "total_count = response.json().get('Data', {}).get('TotalCount', 0)\n",
    "\n",
    "# Second request: fetch all auctions\n",
    "full_data = {\"CategoryId\": \"2\", \"ItemCount\": total_count, \"PageCount\": \"1\"}\n",
    "response_full = requests.post(url, json=full_data, headers=headers)\n",
    "auctions_full = response_full.json().get('Data', {}).get('Auctions', [])\n",
    "\n",
    "# Extract and process auction details for each auction\n",
    "results = []\n",
    "for auction in auctions_full:\n",
    "    auction_id = auction['Id']\n",
    "    auction_details = process_auction_id(auction_id, headers)\n",
    "    if auction_details:\n",
    "        auction.update(auction_details)\n",
    "        results.append(auction)\n",
    "\n",
    "# Combine the results into a DataFrame\n",
    "fieldnames = [\n",
    "    'Id', 'AuctionNumber', 'StartDate', 'EndDate', 'EstimatedPrice', 'StartingPrice',\n",
    "    'IsFirstSale', 'PropertyType', 'NameCategory', 'ShortDescription', 'Description',\n",
    "    'Code', 'Name', 'ZipCode', 'Municipality', 'Cadastral', 'ParcelNumber',\n",
    "    'Status', 'StatusTranslation', 'NumberOfVerifiedUsers', 'ExecutorName'\n",
    "]\n",
    "df = pd.DataFrame(results, columns=fieldnames)\n",
    "\n",
    "# Calculate additional columns\n",
    "df['StartingPrice/EstimatedPrice'] = df['StartingPrice'] / df['EstimatedPrice']\n",
    "df['EstimatedPrice-StartingPrice'] = df['EstimatedPrice'] - df['StartingPrice']\n",
    "\n",
    "# Reorder columns\n",
    "new_order = [\n",
    "    'Id', 'AuctionNumber', 'StartDate', 'EndDate', 'EstimatedPrice', 'StartingPrice',\n",
    "    'StartingPrice/EstimatedPrice', 'EstimatedPrice-StartingPrice', 'IsFirstSale',\n",
    "    'PropertyType', 'NameCategory', 'ShortDescription', 'Description', 'Code', 'Name',\n",
    "    'ZipCode', 'Municipality', 'Status', 'StatusTranslation', 'NumberOfVerifiedUsers',\n",
    "    'ExecutorName'\n",
    "]\n",
    "df = df[new_order]\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "output_file_path = 'aukcije_pokretnosti.csv'\n",
    "df.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Final CSV file created: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d5052-58e0-4f88-bfd4-cacde4061e8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SEGMENTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2dc827-144c-4d1d-a8dd-03d1585995e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved as aukcije_pokretnosti.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Initial setup: URL and headers\n",
    "url = \"https://eaukcija.sud.rs/WebApi.Proxy/api/EAukcija/GetAuctionsByCategoryId\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"accept-language\": \"en,en-US;q=0.9,sr;q=0.8,bs;q=0.7,hr;q=0.6,fi;q=0.5\",\n",
    "    \"content-type\": \"application/json;charset=UTF-8\",\n",
    "}\n",
    "\n",
    "# First request: determine TotalCount\n",
    "initial_data = {\n",
    "    \"CategoryId\": \"2\",\n",
    "    \"ItemCount\": 1,  # Minimal item count to reduce initial load\n",
    "    \"PageCount\": \"1\",\n",
    "}\n",
    "response = requests.post(url, json=initial_data, headers=headers)\n",
    "total_count = response.json().get('Data', {}).get('TotalCount', 0)\n",
    "\n",
    "# Second request: use TotalCount as ItemCount to fetch all auctions\n",
    "full_data = {\n",
    "    \"CategoryId\": \"2\",\n",
    "    \"ItemCount\": total_count,  # Set ItemCount to TotalCount\n",
    "    \"PageCount\": \"1\",\n",
    "}\n",
    "response_full = requests.post(url, json=full_data, headers=headers)\n",
    "auctions_full = response_full.json().get('Data', {}).get('Auctions', [])\n",
    "\n",
    "# Remove the 'Thumbnail' field from each auction\n",
    "for auction in auctions_full:\n",
    "    if 'Thumbnail' in auction:\n",
    "        del auction['Thumbnail']\n",
    "\n",
    "# Save the output as a JSON file named 'aukcije_nepokretnosti.json'\n",
    "json_file_path = 'aukcije_pokretnosti.json'  # Adjust the path as needed\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    # Save the modified auctions data without the Thumbnail field\n",
    "    json.dump({'TotalCount': total_count, 'Auctions': auctions_full}, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Output saved as {json_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324f96a-d928-4223-96c4-7900d1e0eb4c",
   "metadata": {},
   "source": [
    "konvert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ebf2fc-7f40-4b3b-9768-26faa7afd025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created: aukcije_pokretnosti.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Read the JSON file\n",
    "json_file_path = 'aukcije_pokretnosti.json'\n",
    "with open(json_file_path, 'r', encoding='utf-8-sig') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract auctions data, ensure 'Thumbnail' field is excluded\n",
    "auctions = data['Auctions']\n",
    "for auction in auctions:\n",
    "    if 'Thumbnail' in auction:\n",
    "        del auction['Thumbnail']\n",
    "\n",
    "# Manually specify the fieldnames to include all desired fields\n",
    "fieldnames = [\n",
    "    'Id', 'AuctionNumber', 'StartDate', 'EndDate', 'MaxOfferedPrice', 'CurrentPrice',\n",
    "    'StartingPrice', 'ShortDescription', 'Status', 'StatusTranslation', 'NumberOfVerifiedUsers',\n",
    "    'IsFirstSale', 'PropertyType'  # Add any other fields you need\n",
    "]\n",
    "\n",
    "# Write the data to a CSV file\n",
    "csv_file_path = 'aukcije_pokretnosti.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8-sig') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for auction in auctions:\n",
    "        # Fill missing fields with a default value (e.g., None or '')\n",
    "        row = {field: auction.get(field, None) for field in fieldnames}\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file has been created: {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a202df-0426-4ba9-91d5-6806d30fa009",
   "metadata": {},
   "source": [
    "get detalje za pokretnosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a130aa-aa5d-470c-a7f8-b6fc88458c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def remove_base64_fields(data):\n",
    "    \"\"\"Recursively remove Base64 fields from response data.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {key: remove_base64_fields(value) for key, value in data.items() if key.lower() != 'base64'}\n",
    "    elif isinstance(data, list):\n",
    "        return [remove_base64_fields(item) for item in data]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def process_auction_id(auction_id, headers):\n",
    "    \"\"\"Process a single auction ID to fetch, clean, and extract relevant data.\"\"\"\n",
    "    url = \"https://eaukcija.sud.rs/WebApi.Proxy/api/EAukcija/GetMovablePropertyDetails\"\n",
    "    data_payload = {\n",
    "        \"AuctionId\": auction_id,\n",
    "        \"Role\": None,\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data_payload)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        cleaned_data = remove_base64_fields(response.json())\n",
    "        \n",
    "        if 'Data' in cleaned_data:\n",
    "            data_section = cleaned_data['Data']\n",
    "            executor_name = data_section.get(\"ExecutorName\", \"\")\n",
    "            estimated_price = data_section.get(\"EstimatedPrice\", \"\")\n",
    "            auction_number = data_section.get(\"AuctionNumber\", \"\")\n",
    "            description = data_section.get(\"Description\", \"\")\n",
    "            response_auction_id = data_section.get(\"Id\", \"\")\n",
    "            category_data = data_section.get(\"Category\", {})\n",
    "            category_section = {\n",
    "                \"NameCategory\": category_data.get(\"Name\", \"\")\n",
    "            }\n",
    "            place_data = data_section.get(\"Place\", {})\n",
    "            place_section = {\n",
    "                \"Code\": place_data.get(\"Code\", \"\"),\n",
    "                \"Name\": place_data.get(\"Name\", \"\"),\n",
    "                \"ZipCode\": place_data.get(\"ZipCode\", \"\"),\n",
    "                \"Municipality\": place_data.get(\"Municipality\", \"\"),\n",
    "                \"Cadastral\": place_data.get(\"Cadastral\", \"\"),\n",
    "                \"ParcelNumber\": place_data.get(\"ParcelNumber\", \"\")\n",
    "            }\n",
    "            return {\n",
    "                \"ExecutorName\": executor_name,\n",
    "                \"EstimatedPrice\": estimated_price,\n",
    "                \"AuctionNumber\": auction_number,\n",
    "                \"Id\": response_auction_id,  # Use a different variable name if necessary\n",
    "                \"Description\": description,\n",
    "                **place_section,  # Merge dictionaries for flat structure\n",
    "                **category_section\n",
    "            }\n",
    "    else:\n",
    "        print(f\"Failed to process AuctionId: {auction_id}, Status Code: {response.status_code}\")\n",
    "        return {}\n",
    "\n",
    "# File paths\n",
    "csv_file_path = 'aukcije_pokretnosti.csv'\n",
    "json_file_path = 'details_pokretnosti_data.json'\n",
    "output_csv_file_path = 'details_pokretnosti_data.csv'\n",
    "\n",
    "results = []\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"accept-language\": \"en,en-US;q=0.9,sr;q=0.8,bs;q=0.7,hr;q=0.6,fi;q=0.5\",\n",
    "    \"content-type\": \"application/json;charset=UTF-8\",\n",
    "    # Replace with your actual token\n",
    "    \"authorization\": \"bearer YOUR_ACCESS_TOKEN\",\n",
    "}\n",
    "\n",
    "with open(csv_file_path, newline='', encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        auction_id = row['Id']\n",
    "        data = process_auction_id(auction_id, headers)\n",
    "        if data:  # Only add if data is successfully returned\n",
    "            results.append(data)\n",
    "        else:\n",
    "            print(f\"No data for AuctionId: {auction_id}\")\n",
    "\n",
    "# Save results to a JSON file\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Save results to a CSV file\n",
    "with open(output_csv_file_path, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "    fieldnames = ['NameCategory', 'ExecutorName', 'EstimatedPrice', 'AuctionNumber', 'Id', 'Description', 'Code', 'Name', 'ZipCode', 'Municipality', 'Cadastral', 'ParcelNumber']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"All data saved to {json_file_path} and {output_csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb684b-70d7-43b2-a077-ed70ee27d0d4",
   "metadata": {},
   "source": [
    "join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8172273-3a5f-428f-b0f0-af9fa761d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files with utf-8-sig encoding to ensure proper handling of special characters\n",
    "aukcije_nepokretnosti = pd.read_csv('aukcije_pokretnosti.csv', encoding='utf-8-sig')\n",
    "details_data = pd.read_csv('details_pokretnosti_data.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Join the two CSV files on the 'Id' column\n",
    "merged_data = pd.merge(aukcije_nepokretnosti, details_data, on='Id', how='left')\n",
    "\n",
    "# Save the merged data to a new CSV file, using utf-8-sig encoding\n",
    "output_file_path = 'sa_detaljima_aukcije_pokretnosti.csv'\n",
    "merged_data.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f7e60-f417-485b-84cc-98509eebcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('sa_detaljima_aukcije_pokretnosti.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Calculate new columns\n",
    "df['StartingPrice/EstimatedPrice'] = df['StartingPrice'] / df['EstimatedPrice']\n",
    "df['EstimatedPrice-StartingPrice'] = df['EstimatedPrice'] - df['StartingPrice']\n",
    "\n",
    "# Define the new order of the columns\n",
    "new_order = [\n",
    "    'Id', 'AuctionNumber_x', 'StartDate', 'EndDate', 'EstimatedPrice', 'StartingPrice',\n",
    "    'StartingPrice/EstimatedPrice', 'EstimatedPrice-StartingPrice', 'IsFirstSale',\n",
    "    'PropertyType', 'NameCategory', 'ShortDescription', 'Description', 'Code', 'Name',\n",
    "    'ZipCode', 'Municipality', 'Status', 'StatusTranslation', 'NumberOfVerifiedUsers',\n",
    "    'ExecutorName'\n",
    "]\n",
    "\n",
    "# Reorder the dataframe according to the new_order list\n",
    "# Make sure all columns in new_order exist in your dataframe. If not, adjust the list accordingly.\n",
    "df = df[new_order]\n",
    "\n",
    "# Save the modified dataframe back to CSV\n",
    "df.to_csv('sa_detaljima_aukcije_pokretnosti.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497c16c-0b53-4995-af49-0c07b4325db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
